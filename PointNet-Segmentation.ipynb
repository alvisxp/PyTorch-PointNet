{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/home/alvis/.local/bin/jupyter-notebook\", line 5, in <module>\n",
      "\u001b[1;31m    from notebook.notebookapp import main\n",
      "\u001b[1;31m  File \"/home/alvis/.local/lib/python3.10/site-packages/notebook/notebookapp.py\", line 80, in <module>\n",
      "\u001b[1;31m\n",
      "\u001b[1;31m    from .services.contents.manager import ContentsManager\n",
      "\u001b[1;31m  File \"/home/alvis/.local/lib/python3.10/site-packages/notebook/services/contents/manager.py\", line 17, in <module>\n",
      "\u001b[1;31m    from nbformat import sign, validate as validate_nb, ValidationError\n",
      "\u001b[1;31mModuleNotFoundError: No module named 'nbformat'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from path import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import scipy.spatial.distance\n",
    "import math\n",
    "import random\n",
    "import utils\n",
    "\n",
    "root_dir = \"PointNet\"\n",
    "class10_dir = \"PointNet/ModelNet10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def read_pts(file):\n",
    "    verts = np.genfromtxt(file)\n",
    "    return utils.cent_norm(verts)\n",
    "    #return verts\n",
    "\n",
    "def read_seg(file):\n",
    "    verts = np.genfromtxt(file, dtype= (int))\n",
    "    return verts\n",
    "\n",
    "def sample_2000(pts, pts_cat):    \n",
    "    res1 = np.concatenate((pts,np.reshape(pts_cat, (pts_cat.shape[0], 1))), axis= 1)\n",
    "    res = np.asarray(random.choices(res1, weights=None, cum_weights=None, k=2000))\n",
    "    images = res[:, 0:3]\n",
    "    categories = res[:, 3]\n",
    "    categories-=np.ones(categories.shape)\n",
    "    return images, categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=128)\n",
    "        self.fc1 = nn.Conv1d(3,64,1)\n",
    "        self.fc2 = nn.Conv1d(64,128,1) \n",
    "        self.fc3 = nn.Conv1d(128,128,1)\n",
    "        self.fc4 = nn.Conv1d(128,512,1)\n",
    "        self.fc5 = nn.Conv1d(512,2048,1)\n",
    "\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(2048)\n",
    "\n",
    "   def forward(self, input):\n",
    "        n_pts = input.size()[2]\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "        outs = []\n",
    "        \n",
    "        out1 = F.relu(self.bn1(self.fc1(xb)))\n",
    "        outs.append(out1)\n",
    "        out2 = F.relu(self.bn2(self.fc2(out1)))\n",
    "        outs.append(out2)\n",
    "        out3 = F.relu(self.bn3(self.fc3(out2)))\n",
    "        outs.append(out3)\n",
    "        matrix128x128 = self.feature_transform(out3)\n",
    "        \n",
    "        out4 = torch.bmm(torch.transpose(out3,1,2), matrix128x128).transpose(1,2) \n",
    "        outs.append(out4)\n",
    "        out5 = F.relu(self.bn4(self.fc4(out4)))\n",
    "        outs.append(out5)\n",
    "       \n",
    "        xb = self.bn5(self.fc5(out5))\n",
    "        \n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        out6 = nn.Flatten(1)(xb).repeat(n_pts,1,1).transpose(0,2).transpose(0,1)#.repeat(1, 1, n_pts)\n",
    "        outs.append(out6)\n",
    "        \n",
    "        \n",
    "        return outs, matrix3x3, matrix128x128\n",
    "\n",
    "\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "\n",
    "        self.fc1 = nn.Conv1d(3008,256,1) \n",
    "        self.fc2 = nn.Conv1d(256,256,1) \n",
    "        self.fc3 = nn.Conv1d(256,128,1) \n",
    "        self.fc4 = nn.Conv1d(128,4,1) \n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(4)\n",
    "        \n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs, matrix3x3, matrix128x128 = self.transform(input)\n",
    "        stack = torch.cat(inputs,1)\n",
    "        \n",
    "        xb = F.relu(self.bn1(self.fc1(stack)))\n",
    "       \n",
    "        xb = F.relu(self.bn2(self.fc2(xb)))\n",
    "    \n",
    "        xb = F.relu(self.bn3(self.fc3(xb)))\n",
    "        \n",
    "        output = F.relu(self.bn4(self.fc4(xb)))\n",
    "        \n",
    "        return self.logsoftmax(output), matrix3x3, matrix128x128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data.dataset import random_split\n",
    "import utils\n",
    "\n",
    "class Data(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, valid=False, transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.files = []\n",
    "        self.valid=valid\n",
    "\n",
    "        newdir = root_dir + '/datasets/airplane_part_seg/02691156/expert_verified/points_label/'\n",
    "\n",
    "        for file in os.listdir(newdir):\n",
    "            o = {}\n",
    "            o['category'] = newdir + file\n",
    "            o['img_path'] = root_dir + '/datasets/airplane_part_seg/02691156/points/'+ file.replace('.seg', '.pts')\n",
    "            self.files.append(o)\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]['img_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(img_path, 'r') as f:\n",
    "            image1 = read_pts(f)\n",
    "        with open(category, 'r') as f:  \n",
    "            category1 = read_seg(f)\n",
    "        image2, category2 = sample_2000(image1, category1)\n",
    "        if not self.valid:\n",
    "            theta = random.random()*360\n",
    "            image2 = utils.rotation_z(utils.add_noise(image2), theta)\n",
    "        \n",
    "        return {'image': np.array(image2, dtype=\"float32\"), 'category': category2.astype(int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Desktop/Torch/PointNet/datasets/airplane_part_seg/02691156/expert_verified/points_label/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dset \u001b[39m=\u001b[39m Data(root_dir, transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m train_num \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(dset) \u001b[39m*\u001b[39m \u001b[39m0.95\u001b[39m)\n\u001b[1;32m      3\u001b[0m val_num \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(dset) \u001b[39m*\u001b[39m\u001b[39m0.05\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mData.__init__\u001b[0;34m(self, root_dir, valid, transform)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid\u001b[39m=\u001b[39mvalid\n\u001b[1;32m     22\u001b[0m newdir \u001b[39m=\u001b[39m root_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/datasets/airplane_part_seg/02691156/expert_verified/points_label/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(newdir):\n\u001b[1;32m     25\u001b[0m     o \u001b[39m=\u001b[39m {}\n\u001b[1;32m     26\u001b[0m     o[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m newdir \u001b[39m+\u001b[39m file\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Desktop/Torch/PointNet/datasets/airplane_part_seg/02691156/expert_verified/points_label/'"
     ]
    }
   ],
   "source": [
    "dset = Data(root_dir, transform=None)\n",
    "train_num = int(len(dset) * 0.95)\n",
    "val_num = int(len(dset) *0.05)\n",
    "if int(len(dset)) - train_num -  val_num >0 :\n",
    "    train_num = train_num + 1\n",
    "elif int(len(dset)) - train_num -  val_num < 0:\n",
    "    train_num = train_num -1\n",
    "#train_dataset, val_dataset = random_split(dset, [3000, 118])\n",
    "train_dataset, val_dataset = random_split(dset, [train_num, val_num])\n",
    "val_dataset.valid=True\n",
    "\n",
    "print('######### Dataset class created #########')\n",
    "print('Number of images: ', len(dset))\n",
    "print('Sample image shape: ', dset[0]['image'].shape)\n",
    "#print('Sample image points categories', dset[0]['category'], end='\\n\\n')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64)\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(dset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNetSeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m128x128, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id128x128 = torch.eye(128, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id128x128=id128x128.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff128x128 = id128x128-torch.bmm(m128x128,m128x128.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff128x128)) / float(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['image'].to(device), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['image'].to(device), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0) * labels.size(1) ##\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100 * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), root_dir+\"/modelsSeg/\"+str(epoch)+\"_\"+str(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(pointnet, train_loader, val_loader,  save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNetSeg()\n",
    "pointnet.load_state_dict(torch.load(root_dir+\"/modelsSeg/\"+\"14_88.01940298507462\"))\n",
    "pointnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_loader))\n",
    "pred = pointnet(batch['image'].transpose(1,2))\n",
    "pred_np = np.array(torch.argmax(pred[0],1));\n",
    "pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['image'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np==np.array(batch['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (pred_np==np.array(batch['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_acc = np.sum(acc, axis=1) / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z=np.array(batch['image'][0]).T\n",
    "c = np.array(batch['category'][0]).T\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, \n",
    "                                   mode='markers',\n",
    "                                   marker=dict(\n",
    "        size=30,\n",
    "        color=c,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=1.0\n",
    "    ))])\n",
    "fig.update_traces(marker=dict(size=2,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5cca40f0b4fa8e158232184081bf6df1659038bb7add02ac05cc4077427243c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
